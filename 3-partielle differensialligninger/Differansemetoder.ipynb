{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: Partial differential equations and finite difference methods. -->\n",
    "# Sammenligning differansemetoder for deriverte.\n",
    "<!-- dom:AUTHOR: A. Schmeding -->\n",
    "<!-- Author: -->  \n",
    "**A. Schmeding**\n",
    "\n",
    "La oss først laste inn moduler vi trenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy import pi\n",
    "from numpy.linalg import solve, norm    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use a funny plotting style\n",
    "newparams = {'figure.figsize': (6.0, 6.0), 'axes.grid': True,\n",
    "             'lines.markersize': 8, 'lines.linewidth': 2,\n",
    "             'font.size': 14}\n",
    "plt.rcParams.update(newparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerisk derivasjon\n",
    "Dette er hovedverktøyet for endelige differansemetoder. Vi skal teste litt hvor nøyaktig de forskjellige metoder for å finne en approksimasjon til den deriverte er:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f'(x) = \\lim_{h\\rightarrow 0} \\frac{f(x+h)-f(x)}{h}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For liten $h$, høyre side av ligningen approksimerer $f'(x)$. De vanligste metoder for det er disse:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f'(x) \\approx \\left\\{\n",
    "   \\begin{array}{ll}\n",
    "     \\displaystyle \\frac{f(x+h)-f(x)}{h}, \\qquad & \\text{Fremover differanse,} \\\\ \n",
    "     \\displaystyle \\frac{f(x)-f(x-h)}{h}, & \\text{Bakover differanse,} \\\\ \n",
    "     \\displaystyle \\frac{f(x+h)-f(x-h)}{2h}, & \\text{Sentral differanse.}\n",
    "   \\end{array} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f''(x) \\approx \\frac{f(x+h)-2f(x)+f(x-h)}{h^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerisk eksempel:**\n",
    "Test metoden for $f(x)=\\sin(x)$ ved $x=\\frac{\\pi}{4}$.\n",
    "Samenlikne med den eksakte deriverte. Prøv ulike steg lengde, f.eks. $h=0.1, h=0.01, h=0.001$.\n",
    "Se hvordan feilen endrer seg med $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import diags\t        # Greate diagonal matrices\n",
    "from scipy.linalg import solve\t        # Solve linear systems\n",
    "from matplotlib.pyplot import *     \t\n",
    "from mpl_toolkits.mplot3d import Axes3D  # For 3-d plot\n",
    "from matplotlib import cm \n",
    "newparams = {'figure.figsize': (8.0, 4.0), 'axes.grid': True,\n",
    "             'lines.markersize': 8, 'lines.linewidth': 2,\n",
    "             'font.size': 14}\n",
    "rcParams.update(newparams)\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerisk derivasjon\n",
    "\n",
    "# Fremover differanse\n",
    "def diff_forward(f, x, h=0.1):\n",
    "    return (f(x+h)-f(x))/h\n",
    "\n",
    "# Backlengs differanse\n",
    "def diff_backward(f, x, h=0.1):\n",
    "    return (f(x)-f(x-h))/h\n",
    " \n",
    "# Sentral differanse for f'(x):\n",
    "def diff_central(f, x, h=0.1):\n",
    "    return (f(x+h)-f(x-h))/(2*h)\n",
    "# end of diff_central\n",
    "\n",
    "# Sentral differanse for f''(x):\n",
    "def diff2_central(f, x, h=0.1):\n",
    "    return (f(x+h)-2*f(x)+f(x-h))/h**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerisk eksempel 1\n",
    "x = pi/4;\n",
    "df_exact = np.cos(x)\n",
    "ddf_exact = -np.sin(x)\n",
    "h = 0.1\n",
    "f = np.sin\n",
    "df = diff_forward(f, x, h)\n",
    "print('Approximations to the first derivative')\n",
    "print('Forward difference:  df = {:12.8f},   Error = {:10.3e} '.format(df, df_exact-df))\n",
    "df = diff_backward(f, x, h)\n",
    "print('Backward difference: df = {:12.8f},   Error = {:10.3e} '.format(df, df_exact-df))\n",
    "df = diff_central(f, x, h)\n",
    "print('Central difference:  df = {:12.8f},   Error = {:10.3e} '.format(df, df_exact-df))\n",
    "print('Approximation to the second derivative') \n",
    "ddf = diff2_central(f, x, h)\n",
    "print('Central difference:  ddf= {:12.8f},   Error = {:10.3e} '.format(ddf, ddf_exact-ddf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spørsmål/Oppgave:\n",
    "\n",
    "**Sjekk resultater fra siste Python celle: Hva kan dere si om feil?**\n",
    "\n",
    "Diskuter med hverandre: **Hvilken av de tre metoder for å finne en approksimasjon til første deriverte er best?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dette var nå sammenlikning ved akkurat et punkt. Vi skal kjøre mer tests for å finne ut hvordan de forskjellige metoder oppfører seg når vi prøver å lage en mer utfyllende test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step size\n",
    "h = 0.1\n",
    "# Define funksjon (vi tester nå med Kosinus!)\n",
    "f = np.cos\n",
    "# define grid\n",
    "x = np.arange(0, 2*np.pi, h) \n",
    "# compute function\n",
    "y = np.cos(x) \n",
    "\n",
    "# compute vector of forward differences\n",
    "forward_diff = diff_forward(f,x,h) \n",
    "# compute corresponding grid\n",
    "x_diff = x \n",
    "# compute exact solution\n",
    "exact_solution = -np.sin(x_diff) \n",
    "\n",
    "# Plot solution\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(x_diff, forward_diff, '--', \\\n",
    "         label = 'Finite difference approximation')\n",
    "plt.plot(x_diff, exact_solution, \\\n",
    "         label = 'Exact solution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compute max error between \n",
    "# numerical derivative and exact solution\n",
    "max_error = max(abs(exact_solution - forward_diff))\n",
    "print(max_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave:\n",
    "\n",
    "1. Utvid koden oppover slik at det lager en plot av alle tre endelige differanser (i samme bildet), dvs. de tre numeriske approksimasjoner Fremover, baklengs og sentrale differanser sammen med den eksakte løsning. Dere kan bruke feltet nede (hvor vi allerede har limt inn koden fra cellen over).\n",
    "2. Diskuter med hverandre: Passer det dere ser her i eksemplet til deres observasjon fra tidligere eksperiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step size\n",
    "h = 0.1\n",
    "# Define funksjon (vi tester nå med Kosinus!)\n",
    "f = np.cos\n",
    "# define grid\n",
    "x = np.arange(0, 2*np.pi, h) \n",
    "\n",
    "# compute vectors of all differences\n",
    "forward_diff = diff_forward(f,x,h) \n",
    "\n",
    "# compute exact solution\n",
    "exact_solution = -np.sin(x) \n",
    "\n",
    "# Plot solution\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(x, forward_diff, '--', \\\n",
    "         label = 'Forward difference approximation')\n",
    "plt.plot(x, exact_solution, \\\n",
    "         label = 'Exact solution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compute max error between \n",
    "# numerical derivative and exact solution\n",
    "max_error = max(abs(exact_solution - forward_diff))\n",
    "print(max_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det kan være lurt å prøve med forskjellige steglengder $h$, men hvis vi prøver det i siste eksperimentet (prøv f. eks. $h=.01$!) ser vi ingenting visuelt fordi forskjellen mellom løsning og de forskjellige approksimasjoner er så liten.\n",
    "\n",
    "Istedet trenger vi en annen test og må se på en plot som går nærmere i detaljene. Det neste eksperiment viser det for fremover differanser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define step size\n",
    "h = 1\n",
    "# define number of iterations to perform\n",
    "iterations = 20 \n",
    "# list to store our step sizes\n",
    "step_size = [] \n",
    "# list to store max error for each step size\n",
    "max_error = [] \n",
    "\n",
    "for i in range(iterations):\n",
    "    # halve the step size\n",
    "    h /= 2 \n",
    "    # store this step size\n",
    "    step_size.append(h) \n",
    "    # compute new grid\n",
    "    x = np.arange(0, 2 * np.pi, h) \n",
    "    # compute vector of forward differences\n",
    "    fremover_diff = diff_forward(f,x,h) \n",
    "    # compute exact solution\n",
    "    exact_solution = -np.sin(x) \n",
    "    \n",
    "    # Compute max error between \n",
    "    # numerical derivative and exact solution\n",
    "    max_error.append(\\\n",
    "            max(abs(exact_solution - fremover_diff)))\n",
    "\n",
    "# produce log-log plot of max error versus step size\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.xlabel(\"Stepsize h\")\n",
    "plt.ylabel(\"Maks feil\")\n",
    "plt.loglog(step_size, max_error, 'v')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leg merke til at plot bruker $\\log$-skala både for $x$- og $y$-aksen (sjekk Wikipedia [Log skala](https://no.wikipedia.org/wiki/Logaritmisk_skala). En rett linje i vanlig skala betyr at de to variabler er lineært avhengig av hverandre. I log-skala betyr en rett linje (med stigning $1$ som vi ser i bildet!) at sammenheng mellom steglengde $h$ og feil er eksponentiel, dvs. feilen er omtrent i størrelse\n",
    "\n",
    "Feil $\\sim h^1$\n",
    "\n",
    "Så i fremover differanser, feilen minker når vi minker steglengde $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave\n",
    "\n",
    "Prøv samme kode med baklengs differanser og sentrale differanser. Hva kan du si om feilen? \n",
    "I cellen nede har vi allerde limt inn koden brukt tidligere, så dere kan ta utgangspunkt i det.\n",
    "\n",
    "**Hint:** Pass på enheter på aksene!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define step size\n",
    "h = 1\n",
    "# define number of iterations to perform\n",
    "iterations = 20 \n",
    "# list to store our step sizes\n",
    "step_size = [] \n",
    "# list to store max error for each step size\n",
    "max_error = [] \n",
    "\n",
    "for i in range(iterations):\n",
    "    # halve the step size\n",
    "    h /= 2 \n",
    "    # store this step size\n",
    "    step_size.append(h) \n",
    "    # compute new grid\n",
    "    x = np.arange(0, 2 * np.pi, h) \n",
    "    # compute vector of forward differences\n",
    "    fremover_diff = diff_forward(f,x,h) \n",
    "    # compute exact solution\n",
    "    exact_solution = -np.sin(x) \n",
    "    \n",
    "    # Compute max error between \n",
    "    # numerical derivative and exact solution\n",
    "    max_error.append(\\\n",
    "            max(abs(exact_solution - fremover_diff)))\n",
    "\n",
    "# produce log-log plot of max error versus step size\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.xlabel(\"Stepsize h\")\n",
    "plt.ylabel(\"Maks feil\")\n",
    "plt.loglog(step_size, max_error, 'v')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus informasjon: Error analysis\n",
    "In this case the error analysis is quite simple: Do a Taylor expansion of the\n",
    "error around $x$. The Taylor expansion becomes a power series in $h$.\n",
    "\n",
    "\n",
    "The expansion for the error of the forward difference is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "e(x;h) = f'(x) - \\frac{f(x+h)-f(x)}{h}  = f'(x) - \\frac{f(x)+f'(x)h + \\frac{1}{2}f''(\\xi)h^2 - f(x)}{h} = -\\frac{1}{2}f''(\\xi)h\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\xi\\in (x,x+h)$.  \n",
    "\n",
    "The expansion for the error of the central difference is slightly more complicated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "e(x; h) &= f'(x) - \\frac{f(x+h)-f(x-h)}{2h} \\\\ \n",
    "        &= f'(x) \\\\ &- \\frac{\\big(f(x)+f'(x)h + \\frac{1}{2} f''(x)h^2 + \\frac{1}{6} f'''(\\xi_1)h^2 \\big) - \\big(f(x)-f'(x)h + \\frac{1}{2} f''(x)h^2 - \\frac{1}{6} f'''(\\xi_2)h^2\\big)}{2h} \\\\ \n",
    "        &= -\\frac{1}{12}\\big(f'''(\\xi_1) + f'''(\\xi_2)\\big)h^2  \\\\ \n",
    "        &= -\\frac{1}{6}f'''(\\eta)h^2, \\qquad \\qquad  \\eta \\in (x-h, x+h),\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the two remainder terms have been combined by the intermediate value theorem\n",
    "(Result 2 at the end of *Preliminaries*). The error for the approximation of the\n",
    "second order derivative can be found similarly. \n",
    "\n",
    "The order of an approximation is $p$ if there exist a constant $C$ independent on $h$ such that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "|e(h;x) \\leq C h^p,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, it is sufficient to show that the power expansion of the error satisfies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "e(x,h)=C_ph^{p}+ C_{p+1}h^{p+1} + \\dotsm, \\qquad C_p \\not=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward and backward approximations\n",
    "are of order 1, the central differences of order 2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
